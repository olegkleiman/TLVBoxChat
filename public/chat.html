<!DOCTYPE html> 
<html> 
  
<head>
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes, user-scalable=yes">
    <meta http-equiv="Cache-Control" content="no-cache, no-store, must-revalidate" />
    <meta http-equiv="Pragma" content="no-cache" />
    <meta http-equiv="Expires" content="0" />
    <meta charset="UTF-8" />
    <title>עוזרת אישית - עיריית ת"א</title>
    <link rel="shortcut icon" type="image/png" sizes="32x32" href="https://www.tel-aviv.gov.il/_layouts/15/TlvSP2013PublicSite/Images/IriaFavIcon.ico" />
    <style>
        df-messenger {
          /*  direction: rtl; */
          z-index: 999;
          position: fixed;
          --df-messenger-button-titlebar-color: #0a2f79;
          --df-messenger-font-color: #000;
          --df-messenger-font-family: Google Sans;
          --df-messenger-font-size: 14px;
          --df-messenger-chat-background: #f3f6fc;
          --df-messenger-message-user-background: #d3e3fd;
          --df-messenger-message-bot-background: #ecf3fe; 
          --df-messenger-input-background: white;
          --df-messenger-chips-text-wrap: "nowrap"
          bottom: 16px;
          right: 16px; 
        }
    </style>
    <link rel="stylesheet" href="https://www.gstatic.com/dialogflow-console/fast/df-messenger/prod/v1/themes/df-messenger-default.css">    
    <link rel="stylesheet" href="https://fonts.googleapis.com/icon?family=Material+Icons"> 
    <link rel="stylesheet" href="./tlvbox.css">
    <script src="https://www.gstatic.com/dialogflow-console/fast/df-messenger/prod/v1/df-messenger.js"></script>
    <script src="https://unpkg.com/jwt-decode@2.0.4/build/jwt-decode.min.js"></script>
    <!-- <script src="https://cdn.jsdelivr.net/gh/arikw/itm-to-wgs84-converter@1/src/index.js"></script> -->
    <link rel="stylesheet" href="./tlvbox.css">
</head> 
  
<body> 
    <div>Version November 2024 - Omon Ra</div>
    <!-- <div hidden id="jwt">ey..</div> -->
    <div id="count">0</div>
    <div id="location">xx,yy</div>
    <button class="mdc-button mdc-button--raised"
            onClick="expire()">
        <span class="mdc-button__ripple"></span>
        <span class="mdc-button__touch"></span>
        <span class="mdc-button__label">Force Access Token Expiration</span>
    </button>
    <div id="expirationTime"></div>
    <button class="mdc-button mdc-button--raised"
            onClick="newSession()">
        <span class="mdc-button__ripple"></span>
        <span class="mdc-button__label">New Session</span>
    </button>
    <div>
        <video id="vid"></video>
    </div>

    <div>
        <!-- Using intent='' You can use an event handler that will be called for this event and will produce the first agent message. -->
        <!-- session-id	Optional	A session ID. If this is not supplied, the integration will generate a unique ID for each chat dialog. -->
        <df-messenger
            project-id="muni-tlv"
            agent-id="46727f85-4983-4edb-b8b1-55df166837da"
            language-code="he-il"
            max-query-length="-1"
            allow-feedback="all">
            <df-messenger-chat-bubble
                expanded="true"
                chat-title="TLV Box"
                chat-subtitle="עוזרת אישית"
                placeholder-text="טקסט חופשי..."
                chat-title-icon="./assets/img/HAL9001Logo.png"
                allow-fullscreen="always">
            </df-messenger-chat-bubble>
        </df-messenger>
        <!-- <input type="file" accept="image/*" class="message-camera" capture="camera" id="camera">s -->
        <!-- <button onclick="secondScreen()">Second screen</button> -->
        <button id="record" class="message-mic" onclick="openMicrophone()">
            <img alt="Start" id="mic_img" style="border:none;" width="32" height="32" src="https://www.google.com/intl/en/chrome/assets/common/images/content/mic.gif" />
        </button>
        <button id="camera" class="message-camera" onclick="openCamera()">
            <svg xmlns="http://www.w3.org/2000/svg" width="22" height="22" fill="currentColor" viewBox="0 0 256 256">
                <path d="M208,56H180.28L166.65,35.56A8,8,0,0,0,160,32H96a8,8,0,0,0-6.65,3.56L75.71,56H48A24,24,0,0,0,24,80V192a24,24,0,0,0,24,24H208a24,24,0,0,0,24-24V80A24,24,0,0,0,208,56Zm8,136a8,8,0,0,1-8,8H48a8,8,0,0,1-8-8V80a8,8,0,0,1,8-8H80a8,8,0,0,0,6.66-3.56L100.28,48h55.43l13.63,20.44A8,8,0,0,0,176,72h32a8,8,0,0,1,8,8ZM128,88a44,44,0,1,0,44,44A44.05,44.05,0,0,0,128,88Zm0,72a28,28,0,1,1,28-28A28,28,0,0,1,128,160Z">
                </path>
            </svg>
        </button>
        
    </div>

    <script>

        const secondScreen = () => {
            window.open("https://translate.google.com/")
        }

        // globalThis.dfInstallUtils({
        //     'gcs-bucket-upload': {bucketName: 'tlvbox_picture'},
        // });

        const locationDiv = document.getElementById('location');
        const dfMessenger = document.querySelector('df-messenger');
        const micButton = document.getElementById('record');
        const cameraButton = document.getElementById('camera');
        const micImage = document.getElementById('mic_img');
        var currentVoice;
        const countDiv = document.getElementById("count");

        const recognition = new webkitSpeechRecognition();
        recognition.lang = 'he-IL';
        recognition.continuous = false; // when the user stops talking, speech recognition will end.
        recognition.interimResults = false; // only results returned by the recognizer are final and will not change. 
        recognition.onstart = () => {
            console.log("Speech recognition started");
        }
        recognition.onend = () => {
            console.log("Speech recognition ended");
        }
        recognition.onspeechend = () => {
            console.log("Speech ended");
            recognition.stop();
        };      
        recognition.onnomatch = (event) => {
            console.error("I didn't recognize your speech.");
        }; 
        recognition.onerror = (event) => {
            console.error(`Error occurred while transcribing audio: ${event.error}`);
        }
        recognition.onresult = (event) => {
            stopRecording();

            const transcript = event.results[0][0].transcript;
            dfMessenger.renderCustomText(transcript);
            dfMessenger.sendQuery(transcript, false);

            if ('speechSynthesis' in window) {
                let utterance = new SpeechSynthesisUtterance(transcript);
                window.speechSynthesis.onvoiceschanged = () => {
                    var voices = window.speechSynthesis.getVoices();
                    currentVoice = voices[0];
                    utterance.voice = voices[0];
                    utterance.pitch = 1
                    utterance.rate = 0.5
                    speechSynthesis.speak(utterance)
                };
                utterance.onend = function (event) {
                    console.log("SpeechSynthesisUtterance.onend");
                };
                utterance.onerror = function (event) {
                    console.error("SpeechSynthesisUtterance.onerror");
                };
                utterance.voice = currentVoice;
                speechSynthesis.speak(utterance)
            }
        }

        const projectId = 'muni-tlv';
        const startRecording = () => {

            try {
                recognition.start();

                micImage.alt = "Stop";
                micImage.src = "https://www.google.com/intl/en/chrome/assets/common/images/content/mic-animate.gif";
            } catch(ex) {
                console.log(ex.message);
                recognition.stop();
            }
        }
        const stopRecording = () => {
            try {
                recognition.stop();

                micImage.alt = "Start";
                micImage.src = "https://www.google.com/intl/en/chrome/assets/common/images/content/mic.gif";
            } catch(ex) {
                console.log(ex.message);
            }
        }

        // When the record button is clicked, start recording audio
        const openMicrophone = () => {

            const micPermissions = localStorage.getItem("microphonePermissions"); 
            if( !micPermissions ) {
                requestMicrophonePermission()
                localStorage.setItem("microphonePermissions", "true");
                return;
            }   

            if( micImage.alt == "Start" )
                startRecording();
            else
                stopRecording();

        };

        async function requestMicrophonePermission() {
            try {
                const mediaDevices = navigator.mediaDevices;
                if (!mediaDevices || !mediaDevices.getUserMedia) {
                    alert("getUserMedia() not supported.");
                    return;
                }
                // prompts the user for permission to use a microphone
                await navigator.mediaDevices.getUserMedia({ audio: true });
                console.log("Microphone permission granted!");
             } catch(ex) {
                console.error("Microphone permission denied:", ex.message);
            }
        }

        function receiveAccessToken(accessToken) {

            console.log("receiveAccessToken called")
            var token = jwt_decode(accessToken);

            var cnt = parseInt(countDiv.innerText, 10);
            console.log("Count: " + cnt)
            if( cnt == 0 ) {
                dfMessenger.renderCustomText(`${token.name} שלום`)
            }
            countDiv.textContent = cnt + 1;
            localStorage.setItem("accessToken", accessToken);

            const expirationDiv = document.getElementById("expirationTime");
            var d = new Date(token.exp * 1000);
            expirationDiv.innerText = d.toLocaleString()
        }

        function expire() {

                webViewInterface = window.Native
                webViewInterface.refreshAccessToken();

        }

        function newSession()
        {
            dfMessenger.startNewSession({ retainHistory: true });
            location.reload()
        }

        async function openCamera() {

            const cameraPermissions = localStorage.getItem("cameraPermissions"); 
            if( !cameraPermissions ) {
                const mediaStream = await requestCameraPermission();
                
                if( !mediaStream ) {
                    localStorage.setItem("cameraPermissions", "false");
                    return;
                }

                localStorage.setItem("cameraPermissions", "true");

                let video = document.getElementById("vid");
                if ("srcObject" in video) {
                    video.srcObject = mediaStream;
                } else {
                    video.src = window.URL.createObjectURL(mediaStream);
                }
                video.addEventListener("loadedmetadata", () => {
                    video.play();
                });

                return;
            }   
        }

        const requestCameraPermission = async () => {
            try {
                const mediaDevices = navigator.mediaDevices;
                if (!mediaDevices || !mediaDevices.getUserMedia) {
                    alert("getUserMedia() not supported.");
                    return null;
                }
                // prompts the user for permission to use a camera
                return await navigator.mediaDevices.getUserMedia({ 
                    audio: true,
                    video: { facingMode: "environment" } //  rear camera
                 });
             } catch(ex) {
                console.error("Camera permission denied:", ex.message);
                return null;
            }
        }

//                         Accessing the phone's front and rear cameras

// const constraints = {
//   video: {
//     width: { ... },
//     height: { ... },
//     facingMode: "environment"
//   },
// };

// videoStream.getTracks().forEach((track) => {
//   track.stop()
// })                        
            
// Taking screenshots

// // considering there is a
// // <canvas id="canvas"></canvas>
// // tag in the page
// const canvas = document.querySelector('#canvas')
// canvas.width = video.videoWidth
// canvas.height = video.videoHeight
// canvas.getContext('2d').drawImage(video, 0, 0)

// const img = document.createElement('img')
// img.src = canvas.toDataURL('image/png')
// screenshotsContainer.prepend(img)

        function geoSuccess(position) {

                var location = `${position.coords.latitude},${position.coords.longitude}`

                // Comment these 3 lines for location-aware app
               const latitude = 32.081779
               const longitude = 34.780675
               location = `${latitude},${longitude}`

                console.log(location);
                
                locationDiv.innerText = location;
        }

        function geoError(error) {
                //console.error(error.message)
                alert(`Error: ${error.message}`)
        }

        if( !navigator.geolocation ) {
            alert('No geolocation available')
        } else {
            //navigator.geolocation.getCurrentPosition(geoSuccess, geoError);
            const watchID = navigator.geolocation.watchPosition(geoSuccess, geoError);
            console.log(`WatchId: ${watchID}`)
        }

        // window.addEventListener('df-messenger-loaded', function() {

        //     console.log('Messenger is ready.');

        //     const queryParams = {
        //         parameters:{
        //           "jwt": localStorage.getItem("accessToken");,
        //           "User_Authorized": "True",
        //           "userId": '313069486',
        //           }
        //       };

        //     dfMessenger.setQueryParameters(queryParams)
        // });

        dfMessenger.addEventListener('df-file-upload-completed', function (event) {
            // simulates an end-user input that is normally provided to the agent dialog
            // (May also be used to simulate events)

            console.log(event.detail);

            const queryParams = {
                parameters:{
                  "uploaded_file_name": event.detail
                  }
              };

            dfMessenger.setQueryParameters(queryParams)   
            dfMessenger.sendRequest('query','file uploaded');
        });

        dfMessenger.addEventListener('df-upload-file-selected', async (event) => {
            const url = URL.createObjectURL(event.detail.file);
            console.log(`URL of selected file: ${url}`);

            const eventDetail = event.detail;

            // const stream = event.detail.file.stream();
            // const readableStream = await stream.getReader();
            // const chunk = await readableStream.read();
            // const _val = new TextDecoder('utf-8').decode(chunk.value);

            const reader = new FileReader();

            reader.onload = async () => {
                
                try {
                    const parts = dfMessenger.sessionId.split("dfMessenger-");
                    const data = {
                            session_id: parts[1],
                            picture_base64: reader.result
                        }
                    const resp = await fetch('https://tlvbox.azurewebsites.net/api/UploadImage', {
                        method: 'POST',
                        headers: {
                            'Content-Type': 'application/json', 
                        },
                        body: JSON.stringify(data)
                    });
                    console.log(resp);

                    const event = new Event("df-file-upload-completed", {
                        detail: eventDetail
                    });
                    dfMessenger.dispatchEvent(event);

                } catch(ex) {
                    console.error(ex.message);
                }
            }
            reader.onerror = (error) => {
                console.error(error)
            }
            reader.readAsDataURL(event.detail.file);
        });

        window.addEventListener('df-session-id-set', function(event) {
            console.log('Session set');
        });

        dfMessenger.addEventListener('df-chat-open-changed', function(event) {
            console.log(`Chat is ${event.detail.isOpen ? 'open' : 'closed'}`);
            const sendButton = document.getElementById('send-icon-button');
        });
        window.addEventListener('df-messenger-error', function (event) {
            console.log(event.detail.error)
        });
        window.addEventListener('df-request-sent', (event) => {
            console.log('Request', event.detail.data.requestBody);
        });
        window.addEventListener('df-response-received', (event) => {
            console.log(event.detail)
        })
        // window.addEventListener('df-chip-clicked', async (event) => {
        //     console.log(event)
        // })
        window.addEventListener('df-user-input-entered', (event) => {
            
            const jwt = localStorage.getItem("accessToken");

            try {
                const token = jwt_decode(jwt);

                const coordinates = locationDiv.innerText.split(",");
                const latitude = parseFloat(coordinates[0]);
                const longitude = parseFloat(coordinates[1]);

                const queryParams = {
                    parameters:{
                    "jwt": jwt,
                    "userEmail": token["signInNamesInfo.emailAddress"],
                    "userName": token.name,
                    "userId": token["signInNames.citizenId"],
                    "latitude": latitude,
                    "longitude" : longitude
                    }
                };

                dfMessenger.setQueryParameters(queryParams)     
            } catch(ex) {
                console.log(ex.message)
            }

        
        })
        
    </script>
</body> 
  
</html>  